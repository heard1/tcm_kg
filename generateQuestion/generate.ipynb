{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = {\n",
    "    \"症状到病\":[\n",
    "        {\"我{sym1}而且{sym2}，是得了什么病？\":\"O {sym1} O O {sym2} O O O O O O O O\"},\n",
    "        {\"{sym1}和{sym2}说明得了什么病\":\"{sym1} O {sym2} O O O O O O O\"},\n",
    "        {\"{sym1}和{sym2}是什么病的症状？\":\"{sym1} O {sym2} O O O O O O O O\"},\n",
    "        {\"生了什么病会{sym1}、{sym2}\":\"O O O O O O {sym1} O {sym2}\"}\n",
    "    ],\n",
    "    \"症状到药\":[\n",
    "        {\"我{sym1}而且{sym2}，应该吃什么药？\":\"O {sym1} O O {sym2} O O O O O O O O\"},\n",
    "        {\"{sym1}和{sym2}得吃什么治\":\"{sym1} O {sym2} O O O O O\"},\n",
    "        {\"{sym1}和{sym2}吃什么能好？\":\"{sym1} O {sym2} O O O O O\"},\n",
    "        {\"吃什么能治{sym1}、{sym2}\":\"O O O O O {sym1} O {sym2}\"}\n",
    "    ],\n",
    "    \"疾病到药\":[\n",
    "        {\"我得了{dis1}和{dis2}，应该吃什么药？\":\"O O O {dis1} O {dis2} O O O O O O\"},\n",
    "        {\"{dis1}和{dis2}这两个病得吃什么治\":\"{dis1} O {dis2} O O O O O O O O O\"},\n",
    "        {\"得了{dis1}和{dis2}吃什么能好？\":\"O O {dis1} O {dis2} O O O O O\"},\n",
    "        {\"吃什么能治{dis1}、{dis2}两个病\":\"O O O O O {dis1} O {dis2} O O O\"}\n",
    "    ],\n",
    "    \"药到病\":[\n",
    "        {\"{drug1}和{drug2}能治疗什么病？\":\"{drug1} O {drug2} O O O O O O\"},\n",
    "        {\"{drug1}和{drug2}两个药能治疗什么\":\"{drug1} O {drug2} O O O O O O O O\"},\n",
    "        {\"我吃{drug1}和{drug2}能治病吗\":\"O O {drug1} O {drug2} O O O O\"},\n",
    "        {\"吃{drug1}和{drug2}有效果的吧\":\"O {drug1} O {drug2} O O O O O\"}\n",
    "    ],\n",
    "    \"饮片比较\":[\n",
    "        {\"{yp1}和{yp2}哪个比较甜\":\"{yp1} O {yp2} O O O O O\"},\n",
    "        {\"{yp1}和{yp2}两个药材味道如何\":\"{yp1} O {yp2} O O O O O O O O\"},\n",
    "        {\"{yp1}和{yp2}哪个好吃\":\"{yp1} O {yp2} O O O O\"},\n",
    "        {\"{yp1}和{yp2}哪个比较苦\":\"{yp1} O {yp2} O O O O O\"}\n",
    "    ],\n",
    "    \"方剂组成\":[\n",
    "        {\"{fj1}和{fj2}共同包含什么\":\"{fj1} O {fj2} O O O O O O\"},\n",
    "        {\"{fj1}和{fj2}两个方剂有哪些共同点\":\"{fj1} O {fj2} O O O O O O O O O O\"},\n",
    "        {\"{fj1}和{fj2}相同饮片有什么\":\"{fj1} O {fj2} O O O O O O O\"},\n",
    "        {\"{fj1}和{fj2}由什么共同组成\":\"{fj1} O {fj2} O O O O O O O\"}\n",
    "    ],  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#从neo4j拿到 症状、疾病、药材、饮片、方剂\n",
    "cur = ['症状','疾病','药材','饮片','方剂']\n",
    "dic = {}\n",
    "for i in cur:\n",
    "    dic[i]=[]\n",
    "\n",
    "from py2neo import Graph,Node,NodeMatcher,RelationshipMatcher\n",
    "\n",
    "graph = Graph(\n",
    "            host=\"10.15.82.65\",\n",
    "            port=7687,\n",
    "            user=\"neo4j\",\n",
    "            )\n",
    "node_matcher = NodeMatcher(graph)\n",
    "\n",
    "for single in cur:\n",
    "    nodes = node_matcher.match(single)\n",
    "    for node in nodes:\n",
    "        dic[single].append(node['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 100\n",
    "\n",
    "def get_data(templates):\n",
    "    res = []\n",
    "    for label in templates:\n",
    "        template_choice = np.random.choice(templates[label], SAMPLE_SIZE)\n",
    "        texts = [list(_.keys())[0] for _ in template_choice]\n",
    "        tags = [list(_.values())[0] for _ in template_choice]\n",
    "        if \"{sym1}\" in texts[0]:\n",
    "            fit_texts = np.random.choice(dic['症状'], SAMPLE_SIZE)\n",
    "            for i in range(SAMPLE_SIZE):\n",
    "                texts[i] = texts[i].replace('{sym1}',fit_texts[i])\n",
    "                item_len = len(fit_texts[i])\n",
    "                if item_len == 1:\n",
    "                    fit_tag = \"B\"\n",
    "                else:\n",
    "                    fit_tag = \"B \" + \"I \"*(item_len-1)\n",
    "                tags[i] = tags[i].replace('{sym1}',fit_tag.rstrip(\" \"))\n",
    "        if \"{sym2}\" in texts[0]:\n",
    "            fit_texts = np.random.choice(dic['症状'], SAMPLE_SIZE)\n",
    "            for i in range(SAMPLE_SIZE):\n",
    "                texts[i] = texts[i].replace('{sym2}',fit_texts[i])\n",
    "                item_len = len(fit_texts[i])\n",
    "                if item_len == 1:\n",
    "                    fit_tag = \"B\"\n",
    "                else:\n",
    "                    fit_tag = \"B \" + \"I \"*(item_len-1)\n",
    "                tags[i] = tags[i].replace('{sym2}',fit_tag.rstrip(\" \"))\n",
    "                \n",
    "        if \"{dis1}\" in texts[0]:\n",
    "            fit_texts = np.random.choice(dic['疾病'], SAMPLE_SIZE)\n",
    "            for i in range(SAMPLE_SIZE):\n",
    "                texts[i] = texts[i].replace('{dis1}',fit_texts[i])\n",
    "                item_len = len(fit_texts[i])\n",
    "                if item_len == 1:\n",
    "                    fit_tag = \"B\"\n",
    "                else:\n",
    "                    fit_tag = \"B \" + \"I \"*(item_len-1)\n",
    "                tags[i] = tags[i].replace('{dis1}',fit_tag.rstrip(\" \"))\n",
    "        if \"{dis2}\" in texts[0]:\n",
    "            fit_texts = np.random.choice(dic['疾病'], SAMPLE_SIZE)\n",
    "            for i in range(SAMPLE_SIZE):\n",
    "                texts[i] = texts[i].replace('{dis2}',fit_texts[i])\n",
    "                item_len = len(fit_texts[i])\n",
    "                if item_len == 1:\n",
    "                    fit_tag = \"B\"\n",
    "                else:\n",
    "                    fit_tag = \"B \" + \"I \"*(item_len-1)\n",
    "                tags[i] = tags[i].replace('{dis2}',fit_tag.rstrip(\" \"))\n",
    "                     \n",
    "        if \"{drug1}\" in texts[0]:\n",
    "            fit_texts = np.random.choice(dic['药材'], SAMPLE_SIZE)\n",
    "            for i in range(SAMPLE_SIZE):\n",
    "                texts[i] = texts[i].replace('{drug1}',fit_texts[i])\n",
    "                item_len = len(fit_texts[i])\n",
    "                if item_len == 1:\n",
    "                    fit_tag = \"B\"\n",
    "                else:\n",
    "                    fit_tag = \"B \" + \"I \"*(item_len-1)\n",
    "                tags[i] = tags[i].replace('{drug1}',fit_tag.rstrip(\" \"))\n",
    "        if \"{drug2}\" in texts[0]:\n",
    "            fit_texts = np.random.choice(dic['药材'], SAMPLE_SIZE)\n",
    "            for i in range(SAMPLE_SIZE):\n",
    "                texts[i] = texts[i].replace('{drug2}',fit_texts[i])\n",
    "                item_len = len(fit_texts[i])\n",
    "                if item_len == 1:\n",
    "                    fit_tag = \"B\"\n",
    "                else:\n",
    "                    fit_tag = \"B \" + \"I \"*(item_len-1)\n",
    "                tags[i] = tags[i].replace('{drug2}',fit_tag.rstrip(\" \"))\n",
    "                     \n",
    "        if \"{yp1}\" in texts[0]:\n",
    "            fit_texts = np.random.choice(dic['饮片'], SAMPLE_SIZE)\n",
    "            for i in range(SAMPLE_SIZE):\n",
    "                texts[i] = texts[i].replace('{yp1}',fit_texts[i])\n",
    "                item_len = len(fit_texts[i])\n",
    "                if item_len == 1:\n",
    "                    fit_tag = \"B\"\n",
    "                else:\n",
    "                    fit_tag = \"B \" + \"I \"*(item_len-1)\n",
    "                tags[i] = tags[i].replace('{yp1}',fit_tag.rstrip(\" \"))\n",
    "        if \"{yp2}\" in texts[0]:\n",
    "            fit_texts = np.random.choice(dic['饮片'], SAMPLE_SIZE)\n",
    "            for i in range(SAMPLE_SIZE):\n",
    "                texts[i] = texts[i].replace('{yp2}',fit_texts[i])\n",
    "                item_len = len(fit_texts[i])\n",
    "                if item_len == 1:\n",
    "                    fit_tag = \"B\"\n",
    "                else:\n",
    "                    fit_tag = \"B \" + \"I \"*(item_len-1)\n",
    "                tags[i] = tags[i].replace('{yp2}',fit_tag.rstrip(\" \"))   \n",
    "                \n",
    "        if \"{fj1}\" in texts[0]:\n",
    "            fit_texts = np.random.choice(dic['方剂'], SAMPLE_SIZE)\n",
    "            for i in range(SAMPLE_SIZE):\n",
    "                texts[i] = texts[i].replace('{fj1}',fit_texts[i])\n",
    "                item_len = len(fit_texts[i])\n",
    "                if item_len == 1:\n",
    "                    fit_tag = \"B\"\n",
    "                else:\n",
    "                    fit_tag = \"B \" + \"I \"*(item_len-1)\n",
    "                tags[i] = tags[i].replace('{fj1}',fit_tag.rstrip(\" \"))   \n",
    "        if \"{fj2}\" in texts[0]:\n",
    "            fit_texts = np.random.choice(dic['方剂'], SAMPLE_SIZE)\n",
    "            for i in range(SAMPLE_SIZE):\n",
    "                texts[i] = texts[i].replace('{fj2}',fit_texts[i])\n",
    "                item_len = len(fit_texts[i])\n",
    "                if item_len == 1:\n",
    "                    fit_tag = \"B\"\n",
    "                else:\n",
    "                    fit_tag = \"B \" + \"I \"*(item_len-1)\n",
    "                tags[i] = tags[i].replace('{fj2}',fit_tag.rstrip(\" \"))                    \n",
    "                \n",
    "        for text, tag in zip(texts, tags):\n",
    "            res.append([text, label, tag])\n",
    "    np.random.shuffle(res)\n",
    "    res = np.stack(res, axis=-1)\n",
    "    train_texts, train_lables, train_tags = res\n",
    "    return train_texts, train_lables, train_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels, train_tags = get_data(templates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,json\n",
    "write_path = \".\"\n",
    "clf_path = os.path.join(write_path, \"clf_data.json\")\n",
    "ner_path = os.path.join(write_path, \"ner_data.json\")\n",
    "if not os.path.exists(write_path):\n",
    "    os.mkdir(write_path)\n",
    "with open(clf_path,\"w\",encoding=\"utf-8\") as f:\n",
    "    json.dump({\"train_data\":list(train_data),\"train_labels\":list(train_labels)},f,ensure_ascii=False,indent=4)\n",
    "with open(ner_path,\"w\",encoding=\"utf-8\") as f:\n",
    "    json.dump({\"train_data\":list(train_data),\"train_tags\":list(train_tags)},f,ensure_ascii=False,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tem = []\n",
    "for data,tag in zip(train_data, train_tags):\n",
    "    tem.append([data,tag])\n",
    "with open(\"ner_train_data.txt\",\"w\",encoding=\"utf-8\") as f:\n",
    "    json.dump(tem,f,ensure_ascii=False,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
